# ğŸŠâ€â™‚ï¸ **Thread Pools: Reuse, Donâ€™t Recreate**

## ğŸ§© Core Idea: Separation of Concerns
| Role | Responsibility |
|------|----------------|
| **Task (`Runnable`/`Callable`)** | *What* to do (pure logic) |
| **Executor (`ExecutorService`)** | *How* to run it (thread management, queuing, lifecycle) |

âœ… **Benefits**:
- âš¡ **Lower latency**: No thread creation per task  
- ğŸ“‰ **Resource control**: Cap threads (e.g., 10, not 10,000)  
- ğŸ§¹ **Automatic cleanup**: Graceful shutdown, rejected task handling  
- ğŸ“ˆ **Throughput tuning**: Match pool size to workload (CPU vs. I/O bound)

---

## ğŸ› ï¸ Javaâ€™s `ExecutorService` Hierarchy

```java
Executor
 â””â”€â”€ ExecutorService
      â”œâ”€â”€ AbstractExecutorService
      â”‚    â”œâ”€â”€ ThreadPoolExecutor        â† The powerhouse (customizable)
      â”‚    â””â”€â”€ ScheduledThreadPoolExecutor
      â””â”€â”€ ForkJoinPool                   â† For recursive parallelism
```

Letâ€™s explore the **4 built-in factory methods** â€” and when to use each.

---

## âœ… 1. `newFixedThreadPool(n)` â€” Steady Workload

```java
ExecutorService pool = Executors.newFixedThreadPool(4);
```

- âœ… **Fixed size**: Exactly `n` threads  
- ğŸ”„ **Reuse**: Idle threads pick up new tasks  
- ğŸ“¥ **Unbounded queue**: `LinkedBlockingQueue` â€” tasks wait if all busy  
- ğŸ¯ **Best for**: CPU-bound or mixed workloads with predictable load

### Example: Image processing (4-core machine)
```java
ExecutorService pool = Executors.newFixedThreadPool(
    Runtime.getRuntime().availableProcessors() // â† 4 on quad-core
);

List<Future<String>> futures = new ArrayList<>();
for (String img : imagePaths) {
    futures.add(pool.submit(() -> processImage(img)));
}

// Wait for all
for (Future<String> f : futures) {
    System.out.println(f.get()); // Blocks until done
}
pool.shutdown();
```

âš ï¸ **Risk**: If tasks are I/O-bound, threads spend time *waiting* â€” underutilized cores.

---

## âœ… 2. `newCachedThreadPool()` â€” Bursty Workload

```java
ExecutorService pool = Executors.newCachedThreadPool();
```

- ğŸŒŠ **Dynamic size**: 0 â†’ unbounded (scales up/down)  
- â³ **Idle timeout**: Threads die after 60s idle  
- ğŸ“¥ **Synchronous queue**: No queue â€” new task â†’ new thread (if none idle)  
- ğŸ¯ **Best for**: Short-lived, I/O-heavy tasks (e.g., HTTP handlers)

### Example: Web server request handling
```java
ExecutorService serverPool = Executors.newCachedThreadPool();

// Simulate 100 incoming requests
for (int i = 0; i < 100; i++) {
    int reqId = i;
    serverPool.submit(() -> {
        // Simulate I/O: DB call, API fetch
        try { Thread.sleep(10 + (int)(Math.random() * 20)); } 
        catch (InterruptedException e) { Thread.currentThread().interrupt(); }
        System.out.println("Served request " + reqId + " on " 
            + Thread.currentThread().getName());
    });
}
serverPool.shutdown();
```

âš ï¸ **Risk**: Unbounded growth â†’ OOM if load > capacity.

> âœ… **Fix in Java 19+**: Use `Executors.newThreadPerTaskExecutor()` for true unbounded (but still managed).

---

## âœ… 3. `newSingleThreadExecutor()` â€” Sequential Execution

```java
ExecutorService single = Executors.newSingleThreadExecutor();
```

- ğŸ”’ **Exactly 1 thread**  
- ğŸ“¥ **Unbounded queue**: Tasks run *in order*  
- ğŸ¯ **Best for**:  
  - Event logging  
  - Stateful tasks (no concurrency needed)  
  - Replacing `synchronized` blocks with serial execution

### Example: Safe logging without locks
```java
ExecutorService logger = Executors.newSingleThreadExecutor();

// From any thread:
logger.submit(() -> {
    Files.write(logFile, ("[" + Instant.now() + "] " + msg + "\n").getBytes(),
                StandardOpenOption.CREATE, StandardOpenOption.APPEND);
});
```

âœ… Guarantees:  
- No `ConcurrentModificationException`  
- Log entries in submission order  
- No lock contention

---

## âœ… 4. `newScheduledThreadPool(n)` â€” Delayed/Periodic Tasks

```java
ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(2);
```

- ğŸ•’ **Schedule one-time or recurring tasks**  
- ğŸ” **Fixed pool size** (unlike `Timer`, which uses 1 thread)  
- ğŸ¯ **Best for**: Polling, cache refresh, heartbeat

### Example: Cache auto-refresh every 5s
```java
ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);

// Refresh cache every 5 seconds
scheduler.scheduleAtFixedRate(
    this::refreshCache,   // Runnable
    0,                    // initial delay
    5,                    // period
    TimeUnit.SECONDS
);

// One-time cleanup after 30s
scheduler.schedule(this::cleanup, 30, TimeUnit.SECONDS);
```

âš ï¸ **Critical**: Tasks must **not throw exceptions** â€” they kill the scheduler thread!  
âœ… **Always wrap**:
```java
scheduler.scheduleAtFixedRate(() -> {
    try {
        refreshCache();
    } catch (Exception e) {
        log.error("Cache refresh failed", e);
        // Don't rethrow!
    }
}, 0, 5, SECONDS);
```

---

## âš™ï¸ Going Deeper: `ThreadPoolExecutor` â€” Full Control

The factory methods are convenient â€” but sometimes you need precision.

```java
new ThreadPoolExecutor(
    int corePoolSize,      // Min threads to keep alive
    int maximumPoolSize,   // Max threads allowed
    long keepAliveTime,    // Idle time before shrinking (above core)
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler
);
```

### ğŸ”§ Tuning for I/O-bound work (e.g., microservices)
```java
int cores = Runtime.getRuntime().availableProcessors();
int ioThreads = cores * 2; // Heuristic: 2x for I/O wait

ExecutorService pool = new ThreadPoolExecutor(
    cores,          // core: keep at least #cores alive
    ioThreads,      // max: scale up for I/O bursts
    60L, TimeUnit.SECONDS,
    new LinkedBlockingQueue<>(100), // Bounded queue!
    new CustomThreadFactory("api-worker-"),
    new ThreadPoolExecutor.CallerRunsPolicy() // Fallback
);
```

### ğŸ“‰ Why **bounded queues** matter:
| Queue Type | Risk |
|-----------|------|
| `LinkedBlockingQueue()` (unbounded) | OOM if producers >> consumers |
| `ArrayBlockingQueue(n)` (bounded) | Forces backpressure â€” callers block or reject |

#### ğŸ›‘ Rejection Policies (when queue + max threads full):
| Policy | Behavior |
|--------|----------|
| `AbortPolicy` (default) | Throws `RejectedExecutionException` |
| `CallerRunsPolicy` | **Smart fallback**: Task runs on *submitting thread* (slows producer) |
| `DiscardPolicy` | Silently drop task |
| `DiscardOldestPolicy` | Drop oldest in queue, add new |

âœ… **Production tip**: `CallerRunsPolicy` is often safest â€” itâ€™s *self-throttling*.

---

## ğŸ§ª Real-World Demo: Web Crawler with Backpressure

```java
public class WebCrawler {
    // Bounded pool: 10 threads, 20-queue, caller-runs fallback
    private final ExecutorService pool = new ThreadPoolExecutor(
        5, 10, 60L, TimeUnit.SECONDS,
        new ArrayBlockingQueue<>(20),
        r -> {
            Thread t = new Thread(r, "crawler-" + COUNTER.getAndIncrement());
            t.setDaemon(true);
            return t;
        },
        new ThreadPoolExecutor.CallerRunsPolicy()
    );

    private final Set<String> visited = ConcurrentHashMap.newKeySet();

    public void crawl(String url) {
        if (!visited.add(url)) return; // Already seen

        pool.submit(() -> {
            try {
                String html = fetch(url);
                List<String> links = extractLinks(html);
                links.parallelStream()
                     .filter(this::isRelevant)
                     .forEach(this::crawl); // Recursive â€” but bounded!
            } catch (Exception e) {
                System.err.println("Failed: " + url);
            }
        });
    }

    // Shutdown gracefully
    public void shutdown() {
        pool.shutdown();
        try {
            if (!pool.awaitTermination(30, TimeUnit.SECONDS)) {
                pool.shutdownNow();
            }
        } catch (InterruptedException e) {
            pool.shutdownNow();
        }
    }
}
```

âœ… Benefits:  
- No OOM (bounded threads + queue)  
- Self-throttling under load (`CallerRunsPolicy`)  
- Graceful shutdown

---

## ğŸ§­ Thread Pool Best Practices

| Do âœ… | Donâ€™t âŒ |
|------|----------|
| Use `try { ... } finally { pool.shutdown(); }` | Forget to shut down â†’ JVM hangs |
| Prefer bounded queues for production | Use unbounded queues blindly |
| Name threads (`ThreadFactory`) | Leave as "pool-1-thread-1" (debugging hell) |
| Handle exceptions in tasks | Let them bubble (kills thread!) |
| Match pool size to workload: <br> - CPU: `N_cores` <br> - I/O: `N_cores * (1 + wait/compute)` | Use `newCachedThreadPool()` for CPU work |

> ğŸ”¢ **Pool size formula (for mixed workloads)**:  
> \[
> \text{threads} = N_{\text{cores}} \times \left(1 + \frac{\text{wait time}}{\text{compute time}}\right)
> \]  
> e.g., DB call (10ms wait) + 2ms compute â†’ ratio = 5 â†’ 4 cores Ã— 6 = **24 threads**

---

## ğŸš€ The Future: Virtual Threads (Project Loom)

Java 21+ introduces **virtual threads** â€” lightweight threads managed by JVM:

```java
try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {
    IntStream.range(0, 10_000).forEach(i -> {
        executor.submit(() -> {
            Thread.sleep(1000); // Blocks virtual thread, not OS thread!
            System.out.println(i);
            return i;
        });
    });
} // Auto-shutdown
```

âœ… **Game-changer**:  
- Millions of concurrent tasks  
- No pool tuning needed  
- Existing `ExecutorService` API â€” just swap factory

> We can dive deeper into Loom if youâ€™d like â€” itâ€™s the biggest concurrency shift since Java 5.
